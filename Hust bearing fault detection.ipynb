{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ff531-8bbd-42a6-8809-b147caf4ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179596a8-c741-463e-8f7b-0147acfa93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(file):\n",
    "  c = 0\n",
    "  for i in file:\n",
    "    if(i.isalpha()):\n",
    "      c+=1\n",
    "    else:\n",
    "      break\n",
    "  return file[:c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c87375-7b96-415c-b1df-8cd1cd11b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(dir_path,label,path):\n",
    "    try:\n",
    "        mat = scipy.io.loadmat(dir_path+\"/\"+path,appendmat=False)\n",
    "    except:\n",
    "        print(\"Exception occured\")\n",
    "        return\n",
    "\n",
    "    if(\"data\" not in mat.keys() and \"fs\" not in mat.keys() ):\n",
    "        print(\"image could not be generated\")\n",
    "        print(\"Cols are \",mat.keys())\n",
    "        return\n",
    "\n",
    "    mat_data = mat['data']\n",
    "    fs = mat['fs']\n",
    "\n",
    "    num_samples, num_channels = mat_data.shape\n",
    "\n",
    "    size = int(num_samples/50)\n",
    "\n",
    "    for i in range(0,num_samples,size):\n",
    "      data=mat_data[i:i+size]\n",
    "\n",
    "    # Create a figure\n",
    "      fig = plt.figure(frameon = False,clear=True)\n",
    "      fig.set_size_inches(12,8)\n",
    "      ax1 = plt.Axes(fig,[0.,0.,1.,1.])\n",
    "      ax1.set_axis_off()\n",
    "      fig.add_axes(ax1)\n",
    "\n",
    "      data_for_specgram = data[:, 0]\n",
    "      spec, freqs, t, im = ax1.specgram(data_for_specgram, Fs=float(fs), NFFT=256, cmap='magma')\n",
    "\n",
    "\n",
    "      # Save the image\n",
    "      idx = int(i/size)\n",
    "      plt.savefig(\"./imgs/\"+label+\"/\"+path[:-4]+\"_\"+str(idx)+\"_img.png\")\n",
    "    \n",
    "      plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce243d-e38d-4020-930d-e9c455768a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(name):\n",
    "  path = \"./imgs/\"+name\n",
    "  try:\n",
    "    os.mkdir(path)\n",
    "  except:\n",
    "    print(\"Error in creating path for \"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6ee06-d906-4413-968d-c22322f5d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./HUST bearing a practical dataset for ball bearing fault diagnosis/HUST bearing dataset\"\n",
    "\n",
    "files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "s = []\n",
    "\n",
    "print(len(files))\n",
    "\n",
    "for file in files:\n",
    "    label = extract_name(file)\n",
    "    if(label not in s):\n",
    "      print(label)\n",
    "      s.append(label)\n",
    "      create_folder(label)\n",
    "    create_image(path,label,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c3f5c-1b45-4d55-93da-82e7ae339e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a16fa-c235-4e4d-8ef7-4863dd270fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_path(path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n",
    "        labels.append((label))\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d365ddd-e52c-4454-a1e7-af652e50ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "DRIVE_PATH = \"./imgs_50/\"\n",
    "class_labels = listdir(DRIVE_PATH)\n",
    "print(class_labels)\n",
    "\n",
    "for i in class_labels:\n",
    "  with tf.device(\"CPU\"):\n",
    "    images, labels = load_images_from_path(DRIVE_PATH+i, i)\n",
    "    x += images\n",
    "    y += labels\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f164dc-62b7-48c3-85b4-222f71ad4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=0)\n",
    "\n",
    "x_train_norm = np.array(x_train) / 255\n",
    "x_test_norm = np.array(x_test) / 255\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense \n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(x_train_norm, y_train_encoded, validation_data=(x_test_norm, y_test_encoded), batch_size=10, epochs=10) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, ':', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot()\n",
    "plt.show()\n",
    "\n",
    "print(hist.history['accuracy'][-1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134327b-4cab-4abb-9312-dd6819ea179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "x_train_norm = preprocess_input(np.array(x_train))\n",
    "x_test_norm = preprocess_input(np.array(x_test))\n",
    "\n",
    "train_features = base_model.predict(x_train_norm)\n",
    "test_features = base_model.predict(x_test_norm)\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dense(7, activation='softmax'))\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist1 = model1.fit(train_features, y_train_encoded, validation_data=(test_features, y_test_encoded), batch_size=10, epochs=10)\n",
    "\n",
    "acc1 = hist1.history['accuracy']\n",
    "val_acc1 = hist1.history['val_accuracy']\n",
    "epochs1 = range(1, len(acc1) + 1)\n",
    "print(acc1)\n",
    "\n",
    "plt.plot(epochs1, acc1, '-', label='Training Accuracy')\n",
    "plt.plot(epochs1, val_acc1, ':', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef110d-1029-4a6c-95b6-734c11f72b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "x_train_norm = preprocess_input(np.array(x_train))\n",
    "x_test_norm = preprocess_input(np.array(x_test))\n",
    "\n",
    "train_features = base_model.predict(x_train_norm)\n",
    "test_features = base_model.predict(x_test_norm)\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model2.add(Dense(1024, activation='relu'))\n",
    "model2.add(Dense(7, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist2 = model2.fit(train_features, y_train_encoded, validation_data=(test_features, y_test_encoded), batch_size=10, epochs=10)\n",
    "\n",
    "\n",
    "acc2= hist2.history['accuracy']\n",
    "val_acc2 = hist2.history['val_accuracy']\n",
    "epochs2 = range(1, len(acc2) + 1)\n",
    "\n",
    "plt.plot(epochs2, acc2, '-', label='Training Accuracy')\n",
    "plt.plot(epochs2, val_acc2, ':', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a8c2b-1c88-40c2-86ae-e7a6dbbbe8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = acc[-1]*100\n",
    "acc1 = acc1[-1]*100\n",
    "acc2 = acc2[-1]*100\n",
    "\n",
    "plt.bar([\"CNN\",\"MobileNet\",\"VGGNet\"],[acc,acc1,acc2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
